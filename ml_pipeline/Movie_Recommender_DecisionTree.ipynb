{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FiddiCoder/-FIA-Project/blob/main/ml_pipeline/Movie_Recommender_DecisionTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "hApke_Bfi-rj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import Librerie\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn import datasets, linear_model,tree\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download e formattazione dataset film\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/FiddiCoder/-FIA-Project/main/\"\n",
        "FILE_PATH = os.path.join(\"dataset\")\n",
        "FILE_URL1 = DOWNLOAD_ROOT + \"dataset/movies2\"\n",
        "\n",
        "def fetch_file_data1(file_url1=FILE_URL1, file_path1=FILE_PATH):\n",
        "    os.makedirs(file_path1, exist_ok=True)\n",
        "    csv_path1 = os.path.join(file_path1, \"movies2\")\n",
        "    urllib.request.urlretrieve(file_url1, csv_path1)\n",
        "\n",
        "fetch_file_data1()\n",
        "datapath = os.path.join(\"dataset\",\"\")\n",
        "\n",
        "with open('./dataset/movies2', encoding = \"ISO-8859-1\") as content:\n",
        "    colonne = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'imdb_url']\n",
        "    generi = ['unknown', 'action', 'adventure', 'animation', 'children', 'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
        "          'film-noir',  'horror', 'musical', 'mystery', 'romance', 'sci-fi', 'thriller', 'war', 'western']\n",
        "    colonneG = colonne + generi\n",
        "    movies = pd.DataFrame(columns=colonneG)\n",
        "    i = 0\n",
        "    for x in content:\n",
        "        x = x.split(\"|\")\n",
        "        x[-1] = x[-1][:-1]\n",
        "        if x[1][-1] == ' ':\n",
        "            x[1] = x[1][:-1]\n",
        "        movies.loc[i] = [word if word!='' else \"empty\" for word in x]\n",
        "        i = i + 1\n",
        "movies['movie_id'] = movies['movie_id'].astype('int64')\n",
        "movies[generi] = movies[generi].astype('category')\n",
        "\n"
      ],
      "metadata": {
        "id": "x0fjqt_X8iBY",
        "cellView": "form"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data cleaning: Tabelle con feature inutili\n",
        "movies = movies.drop('video_release_date', axis=1)\n",
        "movies = movies.drop('release_date', axis=1)\n",
        "movies = movies.drop('imdb_url', axis=1)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HWZBgvREaK2A"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inserimento colonna target con relativo riempimento\n",
        "movies['like'] = 0\n",
        "\n",
        "for i in range(1600):\n",
        "  if((i % 3) == 0):\n",
        "    movies.loc[i, 'like'] = 1\n",
        "  if((i % 8) == 0):\n",
        "    movies.loc[i , 'like'] = 2\n",
        "  if((i % 7) == 0):\n",
        "     movies.loc[i , 'like'] = 3\n",
        "  if((i % 5) == 0):\n",
        "    movies.loc[i , 'like'] = 4\n",
        "  if((i % 6) == 0):\n",
        "    movies.loc[i , 'like'] = 5\n",
        "\n",
        "\n",
        "movies.head(100)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "phyekA1kaavQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Primo Test: Decision tree\n",
        "\n",
        "#@markdown Risultati scarsi.\n",
        "\n",
        "#@markdown Abbiamo pensato di joinare il dataset dei film con il dataset degli utenti che contiene a sua volta una variabile target (rating) con valori opportunamente riempiti e non inseriti manualmente da noi\n",
        "X = movies.iloc[:,2:20]\n",
        "print(X.columns)\n",
        "y = movies.iloc[:,21:]\n",
        "print(y.columns)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.20, random_state=0)\n",
        "\n",
        "dtree = tree.DecisionTreeClassifier()\n",
        "modello = dtree.fit(X_train.values, y_train)\n",
        "\n",
        "for i in range(1, len(movies)):\n",
        "    movie = movies.iloc[i, 1]\n",
        "    if(movie == 'Turbo: A Power Rangers Movie (1997)'):\n",
        "        movie_1_ind = movies.iloc[i,2:20]\n",
        "    if(movie == 'Dead Man Walking (1995)'):\n",
        "        movie_2_ind = movies.iloc[i,2:20]\n",
        "    if (movie == 'Chasing Amy (1997)'):\n",
        "        movie_3_ind = movies.iloc[i,2:20]\n",
        "\n",
        "print(\"prediction for Turbo: A Power Rangers Movie (1997)\")\n",
        "print(dtree.predict([movie_1_ind]))\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "print(dtree.predict([movie_2_ind]))\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "print(dtree.predict([movie_3_ind]))\n",
        "print(\"\\n\")\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"Cross validation: \\n\",score)\n",
        "print(\"Testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "c2BLRaVnx9rV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download txt utenti e formattazione in dataset\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/FiddiCoder/-FIA-Project/main/\"\n",
        "FILE_PATH = os.path.join(\"dataset\")\n",
        "FILE_URL1 = DOWNLOAD_ROOT + \"dataset/users.user\"\n",
        "\n",
        "def fetch_file_data1(file_url1=FILE_URL1, file_path1=FILE_PATH):\n",
        "    os.makedirs(file_path1, exist_ok=True)\n",
        "    csv_path1 = os.path.join(file_path1, \"users.user\")\n",
        "    urllib.request.urlretrieve(file_url1, csv_path1)\n",
        "\n",
        "fetch_file_data1()\n",
        "datapath = os.path.join(\"dataset\",\"\")\n",
        "\n",
        "userCols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('./dataset/users.user', sep='|', names=userCols)\n"
      ],
      "metadata": {
        "id": "8BHKLaJ7IUPS",
        "cellView": "form"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data cleaning, trasformazione variabili da string a boolean\n",
        "\n",
        "#Drop feature inutile\n",
        "users = users.drop('zip_code', axis=1)\n",
        "\n",
        "#Data cleaning = Eliminazione righe vuote\n",
        "users = users[users['gender'] != 'empty']\n",
        "users = users[users['occupation'] != 'empty']\n",
        "\n",
        "#Colonne occupation e gender trasformate in più colonne coi rispettivi nomi delle variabili per dare loro valori booleani\n",
        "users['occupation'] = users['occupation'].astype('category')\n",
        "users['gender'] = users['gender'].astype('category')\n",
        "one_hot_occ = users.occupation.str.get_dummies()\n",
        "users = users.drop('occupation',axis=1)\n",
        "users = users.join(one_hot_occ,how='inner')\n",
        "one_hot_g = users.gender.str.get_dummies()\n",
        "users = users.drop('gender',axis=1)\n",
        "users = users.join(one_hot_g,how='inner')\n",
        "users.head(5)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NnuqVWMIfj0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download dataset chiave per joinare utenti e film\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/FiddiCoder/-FIA-Project/main/\"\n",
        "FILE_PATH = os.path.join(\"dataset\")\n",
        "FILE_URL1 = DOWNLOAD_ROOT + \"dataset/usersmovies.data\"\n",
        "\n",
        "def fetch_file_data1(file_url1=FILE_URL1, file_path1=FILE_PATH):\n",
        "    os.makedirs(file_path1, exist_ok=True)\n",
        "    csv_path1 = os.path.join(file_path1, \"usersmovies.data\")\n",
        "    urllib.request.urlretrieve(file_url1, csv_path1)\n",
        "\n",
        "fetch_file_data1()\n",
        "datapath = os.path.join(\"dataset\",\"\")\n",
        "\n",
        "colonnekey = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "key = pd.read_csv('./dataset/usersmovies.data', sep='\\t', names=colonnekey)\n",
        "\n",
        "#Drop feature inutile\n",
        "key = key.drop('timestamp', axis=1)\n",
        "key.head(50)"
      ],
      "metadata": {
        "id": "-x8SpRVYMDCD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Drop vecchia colonna target 'like', da ora utilizzeremo 'rating'\n",
        "movies = movies.drop('like', axis=1)"
      ],
      "metadata": {
        "id": "LHYmqtkHN4ik",
        "cellView": "form"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Join colonne utenti e film\n",
        "final_dataset = key.merge(movies, left_on='movie_id', right_on='movie_id', how='inner')\n",
        "final_dataset = final_dataset.merge(users, left_on='user_id', right_on='user_id', how='inner')\n",
        "\n",
        "#Spostiamo la colonna target in ultima posizione\n",
        "sposta_colonna = final_dataset.pop(\"rating\")\n",
        "final_dataset.insert(46, \"rating\", sposta_colonna)\n",
        "\n",
        "final_dataset.head(10)"
      ],
      "metadata": {
        "id": "x3r5OP5LNZXk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Secondo Test: Decision tree\n",
        "#@markdown Risultati ancora scarsi, se non peggiori.\n",
        "\n",
        "#@markdown Abbiamo di conseguenza pensato di trasformare la variabile target in un booleano, affinchè potesse risultare più semplice la classificazione tramite decision tree\n",
        "X = final_dataset.iloc[:,3:46]\n",
        "print(X.columns)\n",
        "y = final_dataset.iloc[:,46:]\n",
        "print(y.columns)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.20, random_state=0)\n",
        "\n",
        "dtree = tree.DecisionTreeClassifier()\n",
        "modello = dtree.fit(X_train.values, y_train)\n",
        "\n",
        "for i in range(1, len(final_dataset)):\n",
        "    movie = final_dataset.iloc[i, 2]\n",
        "    if(movie == 'Raising Arizona (1987)'):\n",
        "        movie_1_ind = final_dataset.iloc[i, 3:46]\n",
        "    if(movie == 'Little Big League (1994)'):\n",
        "        movie_2_ind = final_dataset.iloc[i, 3:46]\n",
        "    if (movie == 'Mighty Aphrodite (1995)'):\n",
        "        movie_3_ind = final_dataset.iloc[i, 3:46]\n",
        "print(\"prediction for Raising Arizona (1987))\")\n",
        "predict = dtree.predict([movie_1_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "predict = dtree.predict([movie_2_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "predict = dtree.predict([movie_3_ind])\n",
        "print(predict)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"cross validation scores: \\n\",score)\n",
        "print(\"testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "predict = dtree.predict(X_test)\n",
        "print('Accuracy modello: {0:0.4f}'.\n",
        "format(accuracy_score(y_test, predict)))\n",
        "\n",
        "cm = confusion_matrix(y_test, predict)\n",
        "print('Confusion matrix\\n\\n', cm)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "B65CpYgDh6no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Trasformazione colonna target in booleana\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(0,0)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(1,0)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(2,0)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(3,1)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(4,1)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(5,1)\n",
        "final_dataset.head(10)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TNC-4bOXhiER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Terzo Test: Decision tree\n",
        "#@markdown Risultati considerevolmente migliori.\n",
        "#@markdown\n",
        "#@markdown Abbiamo pensato di fare Feature Selection per migliorare ulteriormente lo score.\n",
        "X = final_dataset.iloc[:,3:46]\n",
        "print(X.columns)\n",
        "y = final_dataset.iloc[:,46:]\n",
        "print(y.columns)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.20, random_state=0)\n",
        "\n",
        "dtree = tree.DecisionTreeClassifier()\n",
        "modello = dtree.fit(X_train.values, y_train)\n",
        "\n",
        "for i in range(1, len(final_dataset)):\n",
        "    movie = final_dataset.iloc[i, 2]\n",
        "    if(movie == 'Raising Arizona (1987)'):\n",
        "        movie_1_ind = final_dataset.iloc[i, 3:46]\n",
        "    if(movie == 'Little Big League (1994)'):\n",
        "        movie_2_ind = final_dataset.iloc[i, 3:46]\n",
        "    if (movie == 'Mighty Aphrodite (1995)'):\n",
        "        movie_3_ind = final_dataset.iloc[i, 3:46]\n",
        "print(\"prediction for Raising Arizona (1987))\")\n",
        "predict = dtree.predict([movie_1_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "predict = dtree.predict([movie_2_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "predict = dtree.predict([movie_3_ind])\n",
        "print(predict)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"Cross validation: \\n\",score)\n",
        "print(\"Testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "predict = dtree.predict(X_test)\n",
        "print('Accuracy modello: {0:0.4f}'.\n",
        "format(accuracy_score(y_test, predict)))\n",
        "\n",
        "cm = confusion_matrix(y_test, predict)\n",
        "print('Confusion matrix\\n\\n', cm)\n"
      ],
      "metadata": {
        "id": "3dVRP12uOV7c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
